{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34aab030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.geeksforgeeks.org/scrape-linkedin-using-selenium-and-beautiful-soup-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5782f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98645735",
   "metadata": {},
   "source": [
    "## Logging in to LinkedIn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee6c875a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joyce\\AppData\\Local\\Temp\\ipykernel_16024\\2930654737.py:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(ChromeDriverManager().install())\n"
     ]
    }
   ],
   "source": [
    "# Creating a webdriver instance\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98119453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening linkedIn's login page\n",
    "driver.get(\"https://linkedin.com/uas/login\")\n",
    "# waiting for the page to load\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c7c6f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering username\n",
    "username = driver.find_element(By.ID, \"username\")\n",
    "# Enter Your Email Address\n",
    "username.send_keys(\"hzzbsch@gmail.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4d995e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering password\n",
    "pword = driver.find_element(By.ID, \"password\")\n",
    "# Enter Your Password\n",
    "pword.send_keys(\"cs5412\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4038d18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on the log in button\n",
    "# Format (syntax) of writing XPath --> //tagname[@attribute='value']\n",
    "driver.find_element(By.XPATH, \"//button[@type='submit']\").click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad270bd7",
   "metadata": {},
   "source": [
    "## Extracting Job Search Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "162a857a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening job's page\n",
    "# paste the URL of job's page here\n",
    "job_url = \"https://www.linkedin.com/jobs/\"\n",
    "# this will open the link\n",
    "driver.get(job_url)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0c46ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering search keywords\n",
    "search = driver.find_element(By.XPATH, \"//input[starts-with(@id, 'jobs-search-box-keyword-id-ember')]\")\n",
    "search.send_keys(\"software engineer\")\n",
    "time.sleep(2)\n",
    "search.send_keys(Keys.RETURN)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "547a53bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scroll\n",
    "def scroll():\n",
    "    print(\"start scrolling\", end = ' ')\n",
    "    left_panel = driver.find_element(By.CLASS_NAME, \"jobs-search-results-list\")\n",
    "    time.sleep(1)\n",
    "    verical_ordinate = 100\n",
    "    for i in range(0, 10):\n",
    "        print(\".\", end = ' ')\n",
    "        driver.execute_script(\"arguments[0].scrollTop = arguments[1]\", left_panel, verical_ordinate)\n",
    "        verical_ordinate += 1000\n",
    "        time.sleep(1)\n",
    "    print(\"done scrolling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "495d1dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process jobs on one page\n",
    "def process_page():\n",
    "    job_src = driver.page_source\n",
    "    soup = BeautifulSoup(job_src, 'lxml')\n",
    "    # get the list of job titles\n",
    "    jobs_html = soup.find_all('a', {'class': 'job-card-list__title'})\n",
    "\n",
    "    # loop through jobs on this page\n",
    "    for title in jobs_html:\n",
    "        try:\n",
    "            job_data = {}\n",
    "            print(\"processing position: \" + title.text.strip())\n",
    "            job_data[\"position\"] = title.text.strip()\n",
    "\n",
    "            # click on each job to get detailed information\n",
    "            driver.find_element(By.LINK_TEXT, title.text.strip()).click()\n",
    "            time.sleep(2)\n",
    "            detail_src = driver.page_source\n",
    "            soup = BeautifulSoup(detail_src, 'lxml')\n",
    "            detail = soup.find('section', {'class': 'scaffold-layout__detail'})\n",
    "\n",
    "            # get job id\n",
    "            url = driver.current_url\n",
    "            index_start = url.find('currentJobId=') + 13\n",
    "            index_end = url.find('&keywords=')\n",
    "            info_id = url[index_start:index_end] if (index_start != -1 and index_end != -1) else \"\"\n",
    "            job_data[\"job_id\"] = info_id\n",
    "\n",
    "            # get company name\n",
    "            info_company = soup.find('span', {'class': 'jobs-unified-top-card__company-name'})\n",
    "            job_data[\"company\"] = info_company.text.strip() if info_company is not None else \"\"\n",
    "\n",
    "            # get date posted\n",
    "            info_date = soup.find('span', {'class': 'jobs-unified-top-card__posted-date'})\n",
    "            job_data[\"date\"] = info_date.text.strip() if info_date is not None else \"\"\n",
    "\n",
    "            # get type and level\n",
    "            info_type = soup.find('li', {'class': 'jobs-unified-top-card__job-insight'})\n",
    "            job_data[\"type\"] = info_type.text.strip() if info_type is not None else \"\"\n",
    "\n",
    "            # get description\n",
    "            info_description = soup.find('div', {'class': 'jobs-description-content'})\n",
    "            job_data[\"description\"] = info_description.text.strip() if info_description is not None else \"\"\n",
    "            data.append(job_data)\n",
    "        except:\n",
    "            print(\"something wrong here :(\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbad0632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "currently on page: 1\n",
      "start scrolling . . . . . . . . . . done scrolling\n",
      "processing position: CNC Programmer\n",
      "processing position: Software Engineer\n",
      "processing position: Software Engineer III - (E3)\n",
      "processing position: PHP/Java Developer\n",
      "processing position: Mobile Engineer\n",
      "processing position: Senior Full Stack Engineer\n",
      "processing position: Senior Software Engineer\n",
      "processing position: Intern, Software Engineer\n",
      "processing position: Intern, Software Engineer\n",
      "processing position: Azure Data Engineer\n",
      "processing position: Senior Software Engineer\n",
      "processing position: Application Developer\n",
      "processing position: Web Developer\n",
      "processing position: Intern, Software Engineer\n",
      "processing position: Software Engineering Intern\n",
      "processing position: React Native/Full Stack Developer\n",
      "processing position: Sr. Full Stack Engineer\n",
      "processing position: Senior Mobile Developer\n",
      "processing position: Senior Software Engineer, Frontend\n",
      "processing position: Senior System Engineer\n",
      "================================================\n"
     ]
    }
   ],
   "source": [
    "# loop through the pages\n",
    "page_lst = driver.find_element(By.CLASS_NAME, \"artdeco-pagination__pages\")\n",
    "pages = page_lst.find_elements(By.TAG_NAME, \"li\")\n",
    "start = int(pages[0].text)\n",
    "end = int(pages[-1].text)\n",
    "data = []\n",
    "time.sleep(2)\n",
    "\n",
    "for page in range(start, 2):\n",
    "    driver.find_element(By.XPATH, \"//button[@aria-label='Page \" + str(page) + \"']\").click()\n",
    "    time.sleep(2)\n",
    "    print(\"currently on page: \" + str(page))\n",
    "    try:\n",
    "        scroll()\n",
    "        process_page()\n",
    "        print(\"================================================\")\n",
    "    except:\n",
    "        print(\"something wrong here :(\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26210b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_object = json.dumps(data)\n",
    "with open((\"LinkedIn\" + datetime.today().strftime('%Y%m%d%H%M') + \".json\"), \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "05cb71555725a98e85607b684237e5eb53604a5d326527a069b8ff569ca53a78"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
